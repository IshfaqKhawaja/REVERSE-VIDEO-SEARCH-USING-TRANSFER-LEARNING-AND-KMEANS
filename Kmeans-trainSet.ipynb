{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Kmeans-trainSet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"olPK1f4Ny6sY","executionInfo":{"status":"ok","timestamp":1616000383804,"user_tz":-330,"elapsed":26099,"user":{"displayName":"Demo Class","photoUrl":"","userId":"14094445631347838476"}},"outputId":"362789a1-1633-46f1-a8cb-155b0e7aabc2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KVDhNkBfzdCO","executionInfo":{"status":"ok","timestamp":1616000390287,"user_tz":-330,"elapsed":1659,"user":{"displayName":"Demo Class","photoUrl":"","userId":"14094445631347838476"}}},"source":["path = '/content/drive/MyDrive/Abuzer'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Byo_gcQdzLKg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616003043144,"user_tz":-330,"elapsed":2507073,"user":{"displayName":"Demo Class","photoUrl":"","userId":"14094445631347838476"}},"outputId":"cfa29efa-ec25-4bde-9b2e-7adae3ecbdc1"},"source":["import os\n","import glob\n","import time\n","from itertools import zip_longest\n","import datetime\n","import gc\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.neighbors import NearestNeighbors\n","from sklearn.cluster import KMeans\n","import joblib\n","\n","from keras import backend as K\n","from keras.applications.resnet50 import ResNet50\n","from keras.applications.resnet50 import preprocess_input\n","\n","from PIL import Image, ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","\n","\n","img_width, img_height = 128, 128\n","today = datetime.datetime.now()\n","skip_img = np.zeros(shape=(img_width, img_height, 3))\n","\n","f_out = path+'/data/conv_feats.csv'\n","files = glob.glob(path+'/data/images/*/*')\n","knn_file = path+'/data/knn.pkl'\n","kmeans_file = path+'/data/kmeans.pkl'\n","\n","\n","def process_img(f):\n","    try:\n","        img = Image.open(f)   \n","            \n","        if img.mode in ('RGBA', 'LA') or (img.mode == 'P' and 'transparency' in img.info):\n","            img.load()\n","\n","            bg = Image.new(\"RGB\", img.size, (255,255,255))\n","            bg.paste(img, mask=img.split()[3])\n","            img = bg\n","            \n","            if not img.mode == 'RGB':\n","                img = img.convert('RGB')\n","            \n","        elif img.mode != 'RGB':\n","            img = img.convert('RGB')\n","\n","        img_array = np.array(\n","            img.resize(\n","                (img_width, img_height), \n","                Image.ANTIALIAS\n","            )\n","        )\n","\n","        return img_array\n","    \n","    except:\n","        return np.zeros(shape=(img_width, img_height, 3))\n","\n","\n","def make_resnet_conv(input_shape):\n","    base_model = ResNet50(input_shape=input_shape, \n","                          weights='imagenet', \n","                          include_top=False)\n","    for layer in base_model.layers:\n","        layer.trainable = False\n","    \n","    return base_model\n","\n","\n","def grouper(iterable, n, fillvalue=None):\n","    args = [iter(iterable)] * n\n","    return zip_longest(*args, fillvalue=fillvalue)\n","\n","\n","def delete_model(model, clear_session=True):\n","    '''removes model!\n","    '''\n","    del model\n","    gc.collect()\n","    if clear_session: K.clear_session()\n","\n","\n","def process_chunk(list_, f_out, model):\n","    '''\n","    Takes a list of filenames.\n","    '''\n","    if os.path.isfile(f_out):\n","        mode = 'a'\n","        header = False\n","    else:\n","        mode = 'w'\n","        header = True\n","        \n","    np_img = [process_img(_) for _ in list_]\n","    \n","    keep_ind = [i for i, _ in enumerate(np_img) if \n","                np.array_equal(_, skip_img) == False]\n","    \n","    np_img = [_ for i, _ in enumerate(np_img) if i in keep_ind]\n","\n","    if np_img:\n","        np_img = np.array(np_img)\n","    else:\n","        return\n","    \n","    X = preprocess_input(np_img.astype(np.float))\n","    \n","    X_conv = model.predict(X, batch_size=64)\n","\n","    # compress them to 2D, new dims are d0 by d1 * d2 * d3\n","    train_reshape = (X_conv.shape[0], np.prod(X_conv.shape[1:]))\n","    \n","    df = pd.DataFrame(X_conv.reshape(train_reshape))\n","    df['filename'] = [_ for i, _ in enumerate(list_) if i in keep_ind]\n","    \n","    df.to_csv(f_out, index=False, mode=mode, header=header)\n","\n","    \n","\n","def main():\n","    # transform images to convolutional features.\n","    base_model = make_resnet_conv((img_width, img_height, 3))  \n","    for i, _ in enumerate(grouper(files, 1280)):\n","        print(i)\n","        if i != 0:\n","            process_chunk(_, f_out, base_model)\n","        else:\n","            process_chunk(_, f_out, base_model)\n","    delete_model(base_model)\n","    \n","\n","    # read data into a dataframe, separate conv feats and filename!\n","    X = pd.read_csv(f_out)\n","    Y = X['filename']\n","    X_ = X[[_ for _ in X.columns if _ != 'filename']].values.astype(np.float)\n","\n","    # fit the model and serialize it!\n","    # knn = NearestNeighbors(n_neighbors=20, n_jobs=8, algorithm='ball_tree')\n","    # knn.fit(X_)\n","    kmeans = KMeans(algorithm=\"elkan\",n_clusters=5,random_state=0)\n","    kmeans.fit(X_)\n","    # joblib.dump(knn, knn_file)\n","    joblib.dump(kmeans, kmeans_file)\n","\n","main()\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["0\n","1\n","2\n","3\n","4\n","5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a3a98qNIFd29"},"source":[""],"execution_count":null,"outputs":[]}]}